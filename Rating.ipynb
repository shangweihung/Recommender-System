{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict, Counter\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Rating (Biased model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $f = \\alpha + \\beta_{user} + \\beta_{book}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data_Processor():\n",
    "    def __init__(self, filename, mode ='val'):\n",
    "        '''\n",
    "        Initialization\n",
    "        '''\n",
    "        self.data = pd.read_csv(filename)\n",
    "        self.mode = mode\n",
    "        self.usersPerBook = defaultdict(set)\n",
    "        self.booksPerUser = defaultdict(set)\n",
    "        self.alpha_init = 0 \n",
    "\n",
    "        self.beta_user = {}\n",
    "        self.beta_book = {}\n",
    "\n",
    "        self.usersPerBook_rate = defaultdict(list)\n",
    "        self.booksPerUser_rate = defaultdict(list)\n",
    "        self.userbook_rating = {}\n",
    "        \n",
    "        if mode ==  'val':\n",
    "            self.train_set = self.data[:190000]\n",
    "            self.val_set = self.data[190000:]\n",
    "        elif mode == 'test':\n",
    "            self.train_set = self.data\n",
    "            \n",
    "        self.lamda = 0\n",
    "            \n",
    "    def preprocessing(self):\n",
    "        '''\n",
    "        Creater Dictionarys and Sets for the following tasks\n",
    "        '''\n",
    "        for i in self.train_set.values:\n",
    "            user, book, rating = i\n",
    "            self.usersPerBook[book].add(user)\n",
    "            self.booksPerUser[user].add(book)\n",
    "\n",
    "            self.usersPerBook_rate[book].append((user,rating))\n",
    "            self.booksPerUser_rate[user].append((book,rating))\n",
    "\n",
    "            self.userbook_rating[user+book] = rating\n",
    "            self.alpha_init += rating\n",
    "        self.alpha_init/=len(self.train_set)\n",
    "\n",
    "    def model_initial(self):\n",
    "        '''\n",
    "        Initialize parameters of betas\n",
    "\n",
    "        beta_user(dict): how often this user tends to rate higher than mean\n",
    "        beta_book(dict): how often this item is rated higher than mean\n",
    "        '''\n",
    "\n",
    "        for u in self.booksPerUser:\n",
    "            count_high = 0\n",
    "            count = 0\n",
    "            for b in self.booksPerUser_rate[u]:\n",
    "                count+=1\n",
    "                if b[1]>self.alpha_init:\n",
    "                    count_high += 1\n",
    "                else:\n",
    "                    count_high -= 1\n",
    "\n",
    "            self.beta_user[u] = float(count_high)/count\n",
    "\n",
    "        for b in self.usersPerBook:\n",
    "            count_high = 0\n",
    "            count = 0\n",
    "            for u in self.usersPerBook_rate[b]:\n",
    "                count+=1\n",
    "                if u[1]>self.alpha_init:\n",
    "                    count_high += 1\n",
    "                else:\n",
    "                    count_high -= 1\n",
    "\n",
    "            self.beta_book[b] = float(count_high)/count\n",
    "\n",
    "    def optimized_lambda(self):\n",
    "        '''\n",
    "        Find Optimized lambda\n",
    "        \n",
    "        '''\n",
    "        lamda = [i*0.5 for i in range(1,21)]\n",
    "        MSE_lamda = []\n",
    "        for lamb in lamda:\n",
    "\n",
    "            old_MSE = 20\n",
    "            MSE = 10\n",
    "            \n",
    "            beta_user = self.beta_user.copy()\n",
    "            beta_book = self.beta_book.copy()\n",
    "            \n",
    "            alpha = self.alpha_init\n",
    "            while MSE < old_MSE:\n",
    "                old_MSE = MSE\n",
    "                tmp_alpha = 0\n",
    "                for i in self.train_set.values:\n",
    "                    user, book, rating = i\n",
    "                    # update alpha\n",
    "                    tmp_alpha += (rating - (beta_user[user]+beta_book[book]))\n",
    "\n",
    "                alpha = tmp_alpha /len(self.train_set)\n",
    "\n",
    "                # update beta_user\n",
    "                temp_beta_user={}\n",
    "                for u in beta_user:\n",
    "                    temp = sum([self.userbook_rating[u+b] - (alpha+beta_book[b]) for b in self.booksPerUser[u]])\n",
    "                    temp_beta_user[u] = temp/ (lamb + len(self.booksPerUser[u]))\n",
    "\n",
    "                # update beta_book\n",
    "                temp_beta_book={}\n",
    "                for b in beta_book:\n",
    "                    temp = sum([self.userbook_rating[u+b] - (alpha+beta_user[u]) for u in self.usersPerBook[b]])\n",
    "                    temp_beta_book[b] = temp/ (lamb + len(self.usersPerBook[b]))\n",
    "\n",
    "                for u in beta_user:\n",
    "                    beta_user[u] = temp_beta_user[u]\n",
    "                for b in beta_book:\n",
    "                    beta_book[b] = temp_beta_book[b]\n",
    "\n",
    "\n",
    "                # calculate MSE(val)\n",
    "                pred_r = []\n",
    "                label_r = []\n",
    "                error = 0\n",
    "                for l in self.val_set.values:\n",
    "                    u,b,r = l\n",
    "                    label_r.append(r)\n",
    "                    beta_u, beta_i = beta_user.get(u,0), beta_book.get(b,0)\n",
    "                    pred = alpha + beta_u + beta_i\n",
    "                    pred_r.append(pred)\n",
    "                    error += (r - pred)**2\n",
    "                MSE = error/len(pred_r)\n",
    "            print('Lambda = %f - MSE = %f' %(lamb, MSE))\n",
    "            MSE_lamda.append(MSE)\n",
    "            \n",
    "        index_lambda = min(range(len(MSE_lamda)), key=MSE_lamda.__getitem__)\n",
    "        self.lamda = lamda[index_lambda]\n",
    "        print('Minimum of MSE: %f at lambda = %.2f ' % (MSE_lamda[index_lambda], self.lamda))\n",
    "        \n",
    "        return self.lamda\n",
    "    \n",
    "        \n",
    "    def train_model(self, lamb_input, n_epoch = 100):\n",
    "        '''\n",
    "        Train model with optimized lambda\n",
    "        '''\n",
    "        \n",
    "        if self.lamda:\n",
    "            lamb = self.lamda\n",
    "            print('-----Start Training!!-----')\n",
    "        else:\n",
    "            lamb = lamb_input \n",
    "            print('-----Evaluate on Testing!!-----')\n",
    "            \n",
    "        for ite in range(n_epoch):\n",
    "        \n",
    "            tmp_alpha = 0\n",
    "            for i in self.train_set.values:\n",
    "                user, book, rating = i\n",
    "                # update alpha\n",
    "                tmp_alpha += (rating - (self.beta_user[user]+self.beta_book[book]))\n",
    "            alpha = tmp_alpha /len(self.train_set)\n",
    "\n",
    "            # update beta_user\n",
    "            temp_beta_user={}\n",
    "            for u in self.beta_user:\n",
    "                temp = sum([self.userbook_rating[u+b] - (alpha+self.beta_book[b])\\\n",
    "                            for b in self.booksPerUser[u]])\n",
    "                temp_beta_user[u] = temp/ (lamb + len(self.booksPerUser[u]))\n",
    "\n",
    "            # update beta_book\n",
    "            temp_beta_book={}\n",
    "            for b in self.beta_book:\n",
    "                temp = sum([self.userbook_rating[u+b] - (alpha+self.beta_user[u])\\\n",
    "                            for u in self.usersPerBook[b]])\n",
    "                temp_beta_book[b] = temp/ (lamb + len(self.usersPerBook[b]))\n",
    "\n",
    "            for u in self.beta_user:\n",
    "                self.beta_user[u] = temp_beta_user[u]\n",
    "            for b in self.beta_book:\n",
    "                self.beta_book[b] = temp_beta_book[b]\n",
    "\n",
    "                \n",
    "            if self.mode == 'val':\n",
    "                # calculate MSE(val)\n",
    "                pred_r = []\n",
    "                label_r = []\n",
    "                error = 0\n",
    "                for l in self.val_set.values:\n",
    "                    u,b,r = l\n",
    "                    label_r.append(r)\n",
    "                    beta_u, beta_i = self.beta_user.get(u,0), self.beta_book.get(b,0)\n",
    "                    pred = alpha + beta_u + beta_i\n",
    "                    pred_r.append(pred)\n",
    "                    error += (r - pred)**2\n",
    "                MSE = error/len(pred_r)\n",
    "                print('Iter: %f MSE = %f' % (ite,MSE))\n",
    "            \n",
    "            elif self.mode == 'test':\n",
    "                self.pred_test = []\n",
    "                with open(\"assignment1/predictions_Rating.txt\", 'w') as predictions:\n",
    "                    for l in open(\"assignment1/pairs_Rating.txt\"):\n",
    "                        if l.startswith(\"userID\"):\n",
    "                            #header\n",
    "                            predictions.write(l)\n",
    "                            continue\n",
    "\n",
    "                        user,book = l.strip().split('-')\n",
    "                        beta_u, beta_b = self.beta_user.get(user,0), self.beta_book.get(book,0)\n",
    "                        pred = alpha + beta_u + beta_b\n",
    "                        if pred>5:\n",
    "                            pred = 5\n",
    "                        elif pred<0:\n",
    "                            pred = 0\n",
    "                        self.pred_test.append(pred)\n",
    "\n",
    "                        predictions.write(user + '-' + book + ',' + str(pred) + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambda = 0.500000 - MSE = 1.122426\n",
      "Lambda = 1.000000 - MSE = 1.115885\n",
      "Lambda = 1.500000 - MSE = 1.112218\n",
      "Lambda = 2.000000 - MSE = 1.109872\n",
      "Lambda = 2.500000 - MSE = 1.108542\n",
      "Lambda = 3.000000 - MSE = 1.108007\n",
      "Lambda = 3.500000 - MSE = 1.108098\n",
      "Lambda = 4.000000 - MSE = 1.108691\n",
      "Lambda = 4.500000 - MSE = 1.109688\n",
      "Lambda = 5.000000 - MSE = 1.111011\n",
      "Lambda = 5.500000 - MSE = 1.112588\n",
      "Lambda = 6.000000 - MSE = 1.114391\n",
      "Lambda = 6.500000 - MSE = 1.116357\n",
      "Lambda = 7.000000 - MSE = 1.118460\n",
      "Lambda = 7.500000 - MSE = 1.120688\n",
      "Lambda = 8.000000 - MSE = 1.122986\n",
      "Lambda = 8.500000 - MSE = 1.125374\n",
      "Lambda = 9.000000 - MSE = 1.127795\n",
      "Lambda = 9.500000 - MSE = 1.130276\n",
      "Lambda = 10.000000 - MSE = 1.132791\n",
      "Minimum of MSE: 1.108007 at lambda = 3.00 \n"
     ]
    }
   ],
   "source": [
    "filename = \"assignment1/train_Interactions.csv.gz\"\n",
    "Rating_Predictor = Data_Processor(filename, mode = 'val')\n",
    "Rating_Predictor.preprocessing()\n",
    "Rating_Predictor.model_initial()\n",
    "optimized_lambda = Rating_Predictor.optimized_lambda() # Tune parameters  ðœ†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Start Training!!-----\n",
      "Iter: 0.000000 MSE = 1.128488\n",
      "Iter: 1.000000 MSE = 1.118908\n",
      "Iter: 2.000000 MSE = 1.115590\n",
      "Iter: 3.000000 MSE = 1.113445\n",
      "Iter: 4.000000 MSE = 1.111976\n",
      "Iter: 5.000000 MSE = 1.110870\n",
      "Iter: 6.000000 MSE = 1.110125\n",
      "Iter: 7.000000 MSE = 1.109527\n",
      "Iter: 8.000000 MSE = 1.109128\n",
      "Iter: 9.000000 MSE = 1.108803\n",
      "Iter: 10.000000 MSE = 1.108586\n",
      "Iter: 11.000000 MSE = 1.108410\n",
      "Iter: 12.000000 MSE = 1.108293\n",
      "Iter: 13.000000 MSE = 1.108200\n",
      "Iter: 14.000000 MSE = 1.108138\n",
      "Iter: 15.000000 MSE = 1.108090\n",
      "Iter: 16.000000 MSE = 1.108059\n",
      "Iter: 17.000000 MSE = 1.108036\n",
      "Iter: 18.000000 MSE = 1.108022\n",
      "Iter: 19.000000 MSE = 1.108013\n",
      "Iter: 20.000000 MSE = 1.108008\n",
      "Iter: 21.000000 MSE = 1.108005\n",
      "Iter: 22.000000 MSE = 1.108005\n",
      "Iter: 23.000000 MSE = 1.108007\n",
      "Iter: 24.000000 MSE = 1.108009\n",
      "Iter: 25.000000 MSE = 1.108011\n",
      "Iter: 26.000000 MSE = 1.108015\n",
      "Iter: 27.000000 MSE = 1.108018\n",
      "Iter: 28.000000 MSE = 1.108021\n",
      "Iter: 29.000000 MSE = 1.108025\n",
      "Iter: 30.000000 MSE = 1.108028\n",
      "Iter: 31.000000 MSE = 1.108031\n",
      "Iter: 32.000000 MSE = 1.108034\n",
      "Iter: 33.000000 MSE = 1.108037\n",
      "Iter: 34.000000 MSE = 1.108039\n",
      "Iter: 35.000000 MSE = 1.108041\n",
      "Iter: 36.000000 MSE = 1.108044\n",
      "Iter: 37.000000 MSE = 1.108046\n",
      "Iter: 38.000000 MSE = 1.108047\n",
      "Iter: 39.000000 MSE = 1.108049\n",
      "Iter: 40.000000 MSE = 1.108051\n",
      "Iter: 41.000000 MSE = 1.108052\n",
      "Iter: 42.000000 MSE = 1.108053\n",
      "Iter: 43.000000 MSE = 1.108054\n",
      "Iter: 44.000000 MSE = 1.108055\n",
      "Iter: 45.000000 MSE = 1.108056\n",
      "Iter: 46.000000 MSE = 1.108057\n",
      "Iter: 47.000000 MSE = 1.108058\n",
      "Iter: 48.000000 MSE = 1.108059\n",
      "Iter: 49.000000 MSE = 1.108059\n",
      "Iter: 50.000000 MSE = 1.108060\n",
      "Iter: 51.000000 MSE = 1.108060\n",
      "Iter: 52.000000 MSE = 1.108061\n",
      "Iter: 53.000000 MSE = 1.108061\n",
      "Iter: 54.000000 MSE = 1.108062\n",
      "Iter: 55.000000 MSE = 1.108062\n",
      "Iter: 56.000000 MSE = 1.108062\n",
      "Iter: 57.000000 MSE = 1.108063\n",
      "Iter: 58.000000 MSE = 1.108063\n",
      "Iter: 59.000000 MSE = 1.108063\n",
      "Iter: 60.000000 MSE = 1.108063\n",
      "Iter: 61.000000 MSE = 1.108063\n",
      "Iter: 62.000000 MSE = 1.108064\n",
      "Iter: 63.000000 MSE = 1.108064\n",
      "Iter: 64.000000 MSE = 1.108064\n",
      "Iter: 65.000000 MSE = 1.108064\n",
      "Iter: 66.000000 MSE = 1.108064\n",
      "Iter: 67.000000 MSE = 1.108064\n",
      "Iter: 68.000000 MSE = 1.108064\n",
      "Iter: 69.000000 MSE = 1.108064\n",
      "Iter: 70.000000 MSE = 1.108065\n",
      "Iter: 71.000000 MSE = 1.108065\n",
      "Iter: 72.000000 MSE = 1.108065\n",
      "Iter: 73.000000 MSE = 1.108065\n",
      "Iter: 74.000000 MSE = 1.108065\n",
      "Iter: 75.000000 MSE = 1.108065\n",
      "Iter: 76.000000 MSE = 1.108065\n",
      "Iter: 77.000000 MSE = 1.108065\n",
      "Iter: 78.000000 MSE = 1.108065\n",
      "Iter: 79.000000 MSE = 1.108065\n",
      "Iter: 80.000000 MSE = 1.108065\n",
      "Iter: 81.000000 MSE = 1.108065\n",
      "Iter: 82.000000 MSE = 1.108065\n",
      "Iter: 83.000000 MSE = 1.108065\n",
      "Iter: 84.000000 MSE = 1.108065\n",
      "Iter: 85.000000 MSE = 1.108065\n",
      "Iter: 86.000000 MSE = 1.108065\n",
      "Iter: 87.000000 MSE = 1.108065\n",
      "Iter: 88.000000 MSE = 1.108065\n",
      "Iter: 89.000000 MSE = 1.108065\n",
      "Iter: 90.000000 MSE = 1.108065\n",
      "Iter: 91.000000 MSE = 1.108065\n",
      "Iter: 92.000000 MSE = 1.108065\n",
      "Iter: 93.000000 MSE = 1.108065\n",
      "Iter: 94.000000 MSE = 1.108065\n",
      "Iter: 95.000000 MSE = 1.108065\n",
      "Iter: 96.000000 MSE = 1.108065\n",
      "Iter: 97.000000 MSE = 1.108065\n",
      "Iter: 98.000000 MSE = 1.108065\n",
      "Iter: 99.000000 MSE = 1.108065\n"
     ]
    }
   ],
   "source": [
    "Rating_Predictor.train_model(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Evaluate on Testing!!-----\n"
     ]
    }
   ],
   "source": [
    "filename = \"assignment1/train_Interactions.csv.gz\"\n",
    "Rating_Predictor = Data_Processor(filename, mode = 'test')\n",
    "Rating_Predictor.preprocessing()\n",
    "Rating_Predictor.model_initial()\n",
    "Rating_Predictor.train_model(optimized_lambda, n_epoch = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  1.,   0.,   1.,   0.,   3.,   3.,  10.,  11.,  10.,  10.,   8.,\n",
       "         11.,  12.,   6.,  14.,  10.,  10.,  17.,  15.,  15.,  18.,  14.,\n",
       "         25.,  25.,  35.,  52.,  82.,  96., 119., 151., 185., 219., 283.,\n",
       "        356., 456., 489., 553., 595., 652., 686., 685., 668., 627., 643.,\n",
       "        543., 454., 370., 272., 203., 277.]),\n",
       " array([0.03315402, 0.13249094, 0.23182786, 0.33116478, 0.4305017 ,\n",
       "        0.52983862, 0.62917554, 0.72851246, 0.82784938, 0.9271863 ,\n",
       "        1.02652322, 1.12586014, 1.22519706, 1.32453398, 1.4238709 ,\n",
       "        1.52320782, 1.62254474, 1.72188166, 1.82121857, 1.92055549,\n",
       "        2.01989241, 2.11922933, 2.21856625, 2.31790317, 2.41724009,\n",
       "        2.51657701, 2.61591393, 2.71525085, 2.81458777, 2.91392469,\n",
       "        3.01326161, 3.11259853, 3.21193545, 3.31127237, 3.41060929,\n",
       "        3.50994621, 3.60928313, 3.70862005, 3.80795697, 3.90729389,\n",
       "        4.0066308 , 4.10596772, 4.20530464, 4.30464156, 4.40397848,\n",
       "        4.5033154 , 4.60265232, 4.70198924, 4.80132616, 4.90066308,\n",
       "        5.        ]),\n",
       " <a list of 50 Patch objects>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAEQNJREFUeJzt3X+snmV9x/H3Zwjq8Ef5cSBNW1YXG+eyRGAnrAuJ2agafhjbPyTBbNKQJt0fbMG4xNX9s5jsj/KPKMlC0oBb2ZzIcIZGiLMpEGMy0BYqitVRSaUn7WiVH8qIM+h3f5yr89ie9jxPe57z9Fzn/Uqe3Pd93dfzPN87hM9z9bp/nFQVkqR+/da4C5AkjZZBL0mdM+glqXMGvSR1zqCXpM4Z9JLUOYNekjpn0EtS5wx6SercG8ZdAMDFF19cq1evHncZkrSo7Nmz58dVNTFXv7Mi6FevXs3u3bvHXYYkLSpJfjRIP6duJKlzcwZ9kncl2Tvj9dMkH0tyYZKdSZ5tywta/yS5M8n+JE8nuXL0hyFJOpk5g76qflBVl1fV5cAfAq8BXwa2ALuqag2wq20DXAesaa/NwF2jKFySNJhhp27WAT+sqh8B64HtrX07sKGtrwfurWmPA8uSLJ+XaiVJQxs26G8CvtDWL62qwwBteUlrXwEcnPGeqdb2G5JsTrI7ye6jR48OWYYkaVADB32S84APAf82V9dZ2k746yZVta2qJqtqcmJizquDJEmnaZgR/XXAk1X1Qtt+4diUTFseae1TwKoZ71sJHDrTQiVJp2eYoP8Iv562AdgBbGzrG4EHZ7Tf3K6+WQu8cmyKR5K08Aa6YSrJbwPvB/5iRvNW4P4km4DngRtb+8PA9cB+pq/QuWXeqpUkDW2goK+q14CLjmv7CdNX4Rzft4Bb56U6SV1aveWhofof2HrDiCpZGrwzVpI6Z9BLUucMeknqnEEvSZ07Kx5TLEmncrKTt56kHYwjeknqnEEvSZ0z6CWpcwa9JHXOk7GSRmbYO2A1Go7oJalzBr0kdc6pG0nd8br73+SIXpI6Z9BLUucMeknqnEEvSZ3zZKykRcvr9AfjiF6SOmfQS1LnDHpJ6txAQZ9kWZIHknw/yb4kf5zkwiQ7kzzblhe0vklyZ5L9SZ5OcuVoD0GSdCqDjug/C3y1qn4PeA+wD9gC7KqqNcCutg1wHbCmvTYDd81rxZKkocwZ9EneBrwXuAegqn5RVS8D64Htrdt2YENbXw/cW9MeB5YlWT7vlUuSBjLIiP53gaPAPyZ5KsndSc4HLq2qwwBteUnrvwI4OOP9U61NkjQGgwT9G4Argbuq6grgf/j1NM1sMktbndAp2Zxkd5LdR48eHahYSdLwBrlhagqYqqon2vYDTAf9C0mWV9XhNjVzZEb/VTPevxI4dPyHVtU2YBvA5OTkCT8EkhYPb1w6u805oq+q/wYOJnlXa1oHfA/YAWxsbRuBB9v6DuDmdvXNWuCVY1M8kqSFN+gjEP4K+HyS84DngFuY/pG4P8km4Hngxtb3YeB6YD/wWusrSRqTgYK+qvYCk7PsWjdL3wJuPcO6JEnzxDtjJalzBr0kdc6gl6TOGfSS1DmDXpI6Z9BLUucMeknqnEEvSZ0z6CWpc4M+AkHSEueDyxYvR/SS1DmDXpI659SNpCXjZNNPB7besMCVLCxH9JLUOYNekjpn0EtS5wx6SeqcQS9JnTPoJalzBr0kdc6gl6TODRT0SQ4k+U6SvUl2t7YLk+xM8mxbXtDak+TOJPuTPJ3kylEegCTp1IYZ0f9pVV1eVZNtewuwq6rWALvaNsB1wJr22gzcNV/FSpKGdyZTN+uB7W19O7BhRvu9Ne1xYFmS5WfwPZKkMzBo0BfwtSR7kmxubZdW1WGAtrykta8ADs5471RrkySNwaAPNbu6qg4luQTYmeT7p+ibWdrqhE7TPxibAS677LIBy5AkDWugEX1VHWrLI8CXgauAF45NybTlkdZ9Clg14+0rgUOzfOa2qpqsqsmJiYnTPwJJ0inNGfRJzk/y1mPrwAeA7wI7gI2t20bgwba+A7i5XX2zFnjl2BSPJGnhDTJ1cynw5STH+v9rVX01ybeA+5NsAp4Hbmz9HwauB/YDrwG3zHvVkkbGPxnYnzmDvqqeA94zS/tPgHWztBdw67xUJ0k6Y94ZK0mdM+glqXMGvSR1zqCXpM4Z9JLUOYNekjpn0EtS5wx6SercoA81k9QZ74BdOgx6SUveyX70Dmy9YYErGQ2nbiSpcwa9JHXOoJekzhn0ktQ5g16SOmfQS1LnDHpJ6pxBL0mdM+glqXMGvSR1zqCXpM4NHPRJzknyVJKvtO13JHkiybNJvpjkvNb+xra9v+1fPZrSJUmDGGZEfxuwb8b27cAdVbUGeAnY1No3AS9V1TuBO1o/SdKYDBT0SVYCNwB3t+0A1wAPtC7bgQ1tfX3bpu1f1/pLksZg0BH9Z4BPAL9q2xcBL1fV6217CljR1lcABwHa/ldaf0nSGMwZ9Ek+CBypqj0zm2fpWgPsm/m5m5PsTrL76NGjAxUrSRreICP6q4EPJTkA3Mf0lM1ngGVJjv3hkpXAobY+BawCaPvfDrx4/IdW1baqmqyqyYmJiTM6CEnSyc0Z9FX1yapaWVWrgZuAR6rqz4BHgQ+3bhuBB9v6jrZN2/9IVZ0wopckLYwzuY7+b4CPJ9nP9Bz8Pa39HuCi1v5xYMuZlShJOhND/c3YqnoMeKytPwdcNUufnwM3zkNtkqR54J2xktQ5g16SOmfQS1LnDHpJ6txQJ2MlaSlZveWhWdsPbL1hgSs5M47oJalzBr0kdc6gl6TOOUcvde5k88xaOhzRS1LnDHpJ6pxBL0mdM+glqXMGvSR1zqCXpM4Z9JLUOYNekjpn0EtS5wx6SeqcQS9JnTPoJalzBr0kdW7OoE/ypiTfTPLtJM8k+VRrf0eSJ5I8m+SLSc5r7W9s2/vb/tWjPQRJ0qkMMqL/X+CaqnoPcDlwbZK1wO3AHVW1BngJ2NT6bwJeqqp3Ane0fpKkMZkz6Gvaq23z3PYq4Brggda+HdjQ1te3bdr+dUkybxVLkoYy0Bx9knOS7AWOADuBHwIvV9XrrcsUsKKtrwAOArT9rwAXzfKZm5PsTrL76NGjZ3YUkqSTGijoq+qXVXU5sBK4Cnj3bN3acrbRe53QULWtqiaranJiYmLQeiVJQxrqqpuqehl4DFgLLEty7E8RrgQOtfUpYBVA2/924MX5KFaSNLxBrrqZSLKsrb8ZeB+wD3gU+HDrthF4sK3vaNu0/Y9U1QkjeknSwhjkj4MvB7YnOYfpH4b7q+orSb4H3Jfk74GngHta/3uAf06yn+mR/E0jqFuSNKA5g76qngaumKX9Oabn649v/zlw47xUJ2lgq7c8NO4SdJbyzlhJ6twgUzeSpDN0sn9xHdh6w8i/2xG9JHXOEb0kDWmco/PT4Yhekjpn0EtS5wx6SeqcQS9JnTPoJalzBr0kdc6gl6TOGfSS1DmDXpI6Z9BLUucMeknqnEEvSZ0z6CWpcwa9JHXOoJekzvk8emmR8W/DaliO6CWpc3MGfZJVSR5Nsi/JM0lua+0XJtmZ5Nm2vKC1J8mdSfYneTrJlaM+CEnSyQ0yon8d+OuqejewFrg1ye8DW4BdVbUG2NW2Aa4D1rTXZuCuea9akjSwOYO+qg5X1ZNt/WfAPmAFsB7Y3rptBza09fXAvTXtcWBZkuXzXrkkaSBDnYxNshq4AngCuLSqDsP0j0GSS1q3FcDBGW+bam2Hj/uszUyP+LnssstOo3RJOrucrSfKBz4Zm+QtwJeAj1XVT0/VdZa2OqGhaltVTVbV5MTExKBlSJKGNFDQJzmX6ZD/fFX9e2t+4diUTFseae1TwKoZb18JHJqfciVJwxrkqpsA9wD7qurTM3btADa29Y3AgzPab25X36wFXjk2xSNJWniDzNFfDXwU+E6Sva3tb4GtwP1JNgHPAze2fQ8D1wP7gdeAW+a1YknSUOYM+qr6BrPPuwOsm6V/AbeeYV3Skne2ntjT4uOdsZLUOYNekjpn0EtS5wx6SeqcQS9JnTPoJalzBr0kdc6gl6TOGfSS1Dn/Zqw0Zt4Bq1FzRC9JnTPoJalzBr0kdc6gl6TOGfSS1DmDXpI6Z9BLUucMeknqnEEvSZ3zzlhpgXgHrMbFEb0kdW7OoE/yuSRHknx3RtuFSXYmebYtL2jtSXJnkv1Jnk5y5SiLlyTNbZAR/T8B1x7XtgXYVVVrgF1tG+A6YE17bQbump8yJUmna86gr6qvAy8e17we2N7WtwMbZrTfW9MeB5YlWT5fxUqShne6c/SXVtVhgLa8pLWvAA7O6DfV2iRJYzLfJ2MzS1vN2jHZnGR3kt1Hjx6d5zIkScec7uWVLyRZXlWH29TMkdY+Baya0W8lcGi2D6iqbcA2gMnJyVl/DKTFyMsodbY53RH9DmBjW98IPDij/eZ29c1a4JVjUzySpPGYc0Sf5AvAnwAXJ5kC/g7YCtyfZBPwPHBj6/4wcD2wH3gNuGUENUuShjBn0FfVR06ya90sfQu49UyLkiTNHx+BIJ0m5+K1WPgIBEnqnEEvSZ0z6CWpcwa9JHXOoJekzhn0ktQ5g16SOmfQS1LnvGFKOgVvilIPHNFLUucMeknqnEEvSZ0z6CWpc56MlfCkq/rmiF6SOmfQS1LnnLpRl5yKkX7NEb0kdc4RvRaFk43QD2y9YYErkRYfg14j5RSKNH4jCfok1wKfBc4B7q6qraP4nsVm1KPSYUP1VN+7WEbQ/pBIc5v3oE9yDvAPwPuBKeBbSXZU1ffm+7vOVsOGz2IKq8VUq6RpoxjRXwXsr6rnAJLcB6wHlkzQLxaGtrQ0jCLoVwAHZ2xPAX80gu8Bhp9iOFW4nc57JOlsN4qgzyxtdUKnZDOwuW2+muQHQ37PxcCPT1rE7UN+2mm+ZwxOedyd8piXhqV4zOT2Mzru3xmk0yiCfgpYNWN7JXDo+E5VtQ3YdrpfkmR3VU2e7vsXq6V43B7z0rAUjxkW5rhHccPUt4A1Sd6R5DzgJmDHCL5HkjSAeR/RV9XrSf4S+A+mL6/8XFU9M9/fI0kazEiuo6+qh4GHR/HZM5z2tM8itxSP22NeGpbiMcMCHHeqTjhPKknqiA81k6TOLcqgT3Jtkh8k2Z9ky7jrGbUkn0tyJMl3x13LQkmyKsmjSfYleSbJbeOuaSEkeVOSbyb5djvuT427poWS5JwkTyX5yrhrWQhJDiT5TpK9SXaP9LsW29RNe8TCfzHjEQvAR3p+xEKS9wKvAvdW1R+Mu56FkGQ5sLyqnkzyVmAPsKHn/84ASQKcX1WvJjkX+AZwW1U9PubSRi7Jx4FJ4G1V9cFx1zNqSQ4Ak1U18nsHFuOI/v8fsVBVvwCOPWKhW1X1deDFcdexkKrqcFU92dZ/Buxj+q7rrtW0V9vmue21uEZjpyHJSuAG4O5x19KjxRj0sz1iofsAWMqSrAauAJ4YbyULo01h7AWOADuraikc92eATwC/GnchC6iAryXZ054UMDKLMegHesSC+pDkLcCXgI9V1U/HXc9CqKpfVtXlTN9VflWSrqfrknwQOFJVe8ZdywK7uqquBK4Dbm1TtCOxGIN+oEcsaPFrc9RfAj5fVf8+7noWWlW9DDwGXDvmUkbtauBDbc76PuCaJP8y3pJGr6oOteUR4MtMT0uPxGIMeh+xsAS0k5L3APuq6tPjrmehJJlIsqytvxl4H/D98VY1WlX1yapaWVWrmf7/+ZGq+vMxlzVSSc5vFxmQ5HzgA8DIrqpbdEFfVa8Dxx6xsA+4v/dHLCT5AvCfwLuSTCXZNO6aFsDVwEeZHt3tba/rx13UAlgOPJrkaaYHNTuraklcbrjEXAp8I8m3gW8CD1XVV0f1ZYvu8kpJ0nAW3YhekjQcg16SOmfQS1LnDHpJ6pxBL0mdM+glqXMGvSR1zqCXpM79H1PMe28Twy5cAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.hist(Rating_Predictor.pred_test, 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
